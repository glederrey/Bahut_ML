{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jour 2 - Exercice 2 : Premiers modèles de Machine Learning\n",
    "\n",
    "## Objectifs\n",
    "- Comprendre les bases des algorithmes de classification\n",
    "- Implémenter et évaluer différents modèles de classification\n",
    "- Analyser les performances des modèles\n",
    "- Visualiser les résultats avec Plotly\n",
    "- Comprendre les forces et faiblesses de chaque algorithme\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Dans ce notebook, nous allons utiliser les données prétraitées du notebook précédent pour entraîner nos premiers modèles de machine learning. Nous nous concentrerons sur la classification binaire pour prédire si un passager est satisfait ou non de son vol. Nous explorerons plusieurs algorithmes de classification et comparerons leurs performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement et préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Bibliothèques pour le machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Métriques d'évaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "\n",
    "# Pour afficher plus de colonnes dans les DataFrames\n",
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du jeu de données\n",
    "df = pd.read_csv('../../data/passenger_satisfaction/train.csv')\n",
    "\n",
    "# Affichage des premières lignes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de la distribution de la variable cible\n",
    "target_counts = df['Satisfaction'].value_counts()\n",
    "\n",
    "fig = px.pie(values=target_counts.values, \n",
    "             names=target_counts.index, \n",
    "             title='Distribution de la satisfaction des passagers',\n",
    "             color_discrete_sequence=px.colors.qualitative.Set3)\n",
    "\n",
    "fig.update_traces(textinfo='percent+label')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prétraitement des données\n",
    "\n",
    "Nous allons reprendre les étapes de prétraitement du notebook précédent pour préparer nos données pour le machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traitement des valeurs manquantes\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Valeurs manquantes par colonne:\")\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage de la variable cible\n",
    "le = LabelEncoder()\n",
    "df['Satisfaction_encoded'] = le.fit_transform(df['Satisfaction'])\n",
    "print(f\"Classes encodées: {dict(zip(le.classes_, range(len(le.classes_))))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Création du pipeline de prétraitement\n",
    "\n",
    "Nous allons créer un pipeline de prétraitement pour automatiser la transformation des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identification des types de colonnes\n",
    "# Suppression des colonnes ID et Satisfaction (variable cible)\n",
    "df_features = df.drop(['ID', 'Satisfaction', 'Satisfaction_encoded'], axis=1)\n",
    "\n",
    "# Identification des colonnes numériques et catégorielles\n",
    "numeric_features = df_features.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = df_features.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Caractéristiques numériques: {numeric_features}\")\n",
    "print(f\"Caractéristiques catégorielles: {categorical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du pipeline de prétraitement\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Imputation des valeurs manquantes\n",
    "    ('scaler', StandardScaler())  # Standardisation des données numériques\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Imputation des valeurs manquantes\n",
    "    ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore'))  # One-hot encoding\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Création de X (features) et y (variable cible)\n",
    "X = df.drop(['ID', 'Satisfaction', 'Satisfaction_encoded'], axis=1)\n",
    "y = df['Satisfaction_encoded']\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Taille de l'ensemble d'entraînement: {X_train.shape}\")\n",
    "print(f\"Taille de l'ensemble de validation: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application du prétraitement\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_val_preprocessed = preprocessor.transform(X_val)\n",
    "\n",
    "print(f\"Forme des données d'entraînement prétraitées: {X_train_preprocessed.shape}\")\n",
    "print(f\"Forme des données de validation prétraitées: {X_val_preprocessed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fonction d'évaluation des modèles\n",
    "\n",
    "Nous allons créer une fonction pour évaluer les performances des différents modèles de manière cohérente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_val, y_train, y_val, model_name):\n",
    "    # Entraînement du modèle\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Prédictions sur l'ensemble d'entraînement et de validation\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calcul des métriques\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    val_precision = precision_score(y_val, y_val_pred)\n",
    "    \n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    val_recall = recall_score(y_val, y_val_pred)\n",
    "    \n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "    val_f1 = f1_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Affichage des métriques\n",
    "    print(f\"Performances du modèle {model_name}:\")\n",
    "    print(f\"Accuracy - Train: {train_accuracy:.4f}, Validation: {val_accuracy:.4f}\")\n",
    "    print(f\"Precision - Train: {train_precision:.4f}, Validation: {val_precision:.4f}\")\n",
    "    print(f\"Recall - Train: {train_recall:.4f}, Validation: {val_recall:.4f}\")\n",
    "    print(f\"F1 Score - Train: {train_f1:.4f}, Validation: {val_f1:.4f}\")\n",
    "    print(\"\\nRapport de classification sur l'ensemble de validation:\")\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    \n",
    "    # Matrice de confusion\n",
    "    cm = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # Visualisation de la matrice de confusion avec Plotly\n",
    "    fig = px.imshow(cm, \n",
    "                    labels=dict(x=\"Prédiction\", y=\"Réalité\", color=\"Nombre\"),\n",
    "                    x=['Non satisfait', 'Satisfait'],\n",
    "                    y=['Non satisfait', 'Satisfait'],\n",
    "                    text_auto=True,\n",
    "                    title=f\"Matrice de confusion - {model_name}\",\n",
    "                    color_continuous_scale='Blues')\n",
    "    fig.update_layout(\n",
    "        title_text=f\"Matrice de confusion - {model_name}\",\n",
    "        xaxis_title=\"Prédiction\",\n",
    "        yaxis_title=\"Réalité\",\n",
    "        coloraxis_colorbar=dict(title=\"Nombre\"),\n",
    "        height=800,\n",
    "        width=800\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    # Courbe ROC si le modèle peut prédire des probabilités\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_val, y_val_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=f'{model_name} (AUC = {roc_auc:.4f})'))\n",
    "        fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Aléatoire', line=dict(dash='dash', color='gray')))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=f'Courbe ROC - {model_name}',\n",
    "            xaxis_title='Taux de faux positifs',\n",
    "            yaxis_title='Taux de vrais positifs',\n",
    "            legend=dict(x=0.7, y=0.1),\n",
    "            width=1000,\n",
    "            height=800\n",
    "        )\n",
    "        fig.show()\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'name': model_name,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'train_precision': train_precision,\n",
    "        'val_precision': val_precision,\n",
    "        'train_recall': train_recall,\n",
    "        'val_recall': val_recall,\n",
    "        'train_f1': train_f1,\n",
    "        'val_f1': val_f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implémentation des modèles de classification\n",
    "\n",
    "Nous allons implémenter plusieurs modèles de classification et évaluer leurs performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Modèle de base : Dummy Classifier\n",
    "\n",
    "Commençons par un modèle de base simple pour établir une référence de performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Création du modèle de base (stratégie la plus fréquente)\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "\n",
    "# Évaluation du modèle\n",
    "dummy_results = evaluate_model(dummy_clf, X_train_preprocessed, X_val_preprocessed, y_train, y_val, \"Dummy Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Régression Logistique\n",
    "\n",
    "La régression logistique est un algorithme simple mais efficace pour la classification binaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Création du modèle de régression logistique\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Évaluation du modèle\n",
    "log_reg_results = evaluate_model(log_reg, X_train_preprocessed, X_val_preprocessed, y_train, y_val, \"Régression Logistique\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Arbre de décision\n",
    "\n",
    "Les arbres de décision sont des modèles intuitifs qui peuvent capturer des relations non linéaires dans les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Création du modèle d'arbre de décision\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Évaluation du modèle\n",
    "dt_results = evaluate_model(dt_clf, X_train_preprocessed, X_val_preprocessed, y_train, y_val, \"Arbre de Décision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Random Forest\n",
    "\n",
    "Random Forest est un ensemble d'arbres de décision qui peut améliorer les performances par rapport à un seul arbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Création du modèle Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Évaluation du modèle\n",
    "rf_results = evaluate_model(rf_clf, X_train_preprocessed, X_val_preprocessed, y_train, y_val, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparaison des modèles\n",
    "\n",
    "Comparons maintenant les performances des différents modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un DataFrame pour comparer les modèles\n",
    "results = [dummy_results, log_reg_results, dt_results, rf_results]\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Modèle': [result['name'] for result in results],\n",
    "    'Accuracy (Train)': [result['train_accuracy'] for result in results],\n",
    "    'Accuracy (Validation)': [result['val_accuracy'] for result in results],\n",
    "    'Precision (Validation)': [result['val_precision'] for result in results],\n",
    "    'Recall (Validation)': [result['val_recall'] for result in results],\n",
    "    'F1 Score (Validation)': [result['val_f1'] for result in results]\n",
    "})\n",
    "\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des performances des modèles\n",
    "metrics = ['Accuracy (Validation)', 'Precision (Validation)', 'Recall (Validation)', 'F1 Score (Validation)']\n",
    "model_names = comparison_df['Modèle']\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for metric in metrics:\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=model_names,\n",
    "        y=comparison_df[metric],\n",
    "        name=metric\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Comparaison des performances des modèles',\n",
    "    xaxis_title='Modèle',\n",
    "    yaxis_title='Score',\n",
    "    barmode='group',\n",
    "    width=900,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyse des caractéristiques importantes\n",
    "\n",
    "Analysons les caractéristiques les plus importantes pour la prédiction selon le modèle Random Forest, qui a généralement de bonnes performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtention des noms des caractéristiques après transformation\n",
    "# Pour les caractéristiques numériques\n",
    "numeric_features_transformed = numeric_features\n",
    "\n",
    "# Pour les caractéristiques catégorielles (après one-hot encoding)\n",
    "categorical_features_transformed = []\n",
    "for cat_feature in categorical_features:\n",
    "    # Obtention des catégories uniques pour chaque caractéristique catégorielle\n",
    "    unique_categories = df[cat_feature].unique()\n",
    "    # Création des noms de colonnes après one-hot encoding (en excluant la première catégorie)\n",
    "    for category in unique_categories[1:]:\n",
    "        categorical_features_transformed.append(f\"{cat_feature}_{category}\")\n",
    "\n",
    "# Combinaison des noms de caractéristiques\n",
    "all_features_transformed = numeric_features_transformed + categorical_features_transformed\n",
    "\n",
    "# Vérification de la longueur\n",
    "print(f\"Nombre de caractéristiques après transformation: {len(all_features_transformed)}\")\n",
    "print(f\"Forme des données prétraitées: {X_train_preprocessed.shape[1]}\")\n",
    "\n",
    "# Ajustement si nécessaire (si les dimensions ne correspondent pas)\n",
    "if len(all_features_transformed) != X_train_preprocessed.shape[1]:\n",
    "    print(\"Attention: Le nombre de noms de caractéristiques ne correspond pas à la dimension des données prétraitées.\")\n",
    "    # Utilisation d'indices numériques si les noms ne correspondent pas\n",
    "    all_features_transformed = [f\"Feature_{i}\" for i in range(X_train_preprocessed.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des importances des caractéristiques du modèle Random Forest\n",
    "feature_importances = rf_clf.feature_importances_\n",
    "\n",
    "# Création d'un DataFrame pour visualiser les importances\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': all_features_transformed,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Affichage des 15 caractéristiques les plus importantes\n",
    "top_15_features = importance_df.head(15)\n",
    "top_15_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des 15 caractéristiques les plus importantes\n",
    "fig = px.bar(top_15_features, \n",
    "             x='Importance', \n",
    "             y='Feature', \n",
    "             orientation='h',\n",
    "             title='Top 15 des caractéristiques les plus importantes',\n",
    "             color='Importance',\n",
    "             color_continuous_scale='Viridis')\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Importance',\n",
    "    yaxis_title='Caractéristique',\n",
    "    width=800,\n",
    "    height=500,\n",
    "    yaxis={'categoryorder':'total ascending'}\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyse des erreurs de prédiction\n",
    "\n",
    "Analysons les cas où notre meilleur modèle (Random Forest) fait des erreurs de prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions du modèle Random Forest sur l'ensemble de validation\n",
    "y_val_pred_rf = rf_clf.predict(X_val_preprocessed)\n",
    "\n",
    "# Identification des erreurs\n",
    "errors = y_val != y_val_pred_rf\n",
    "X_val_errors = X_val[errors]\n",
    "y_val_errors = y_val[errors]\n",
    "y_val_pred_errors = y_val_pred_rf[errors]\n",
    "\n",
    "print(f\"Nombre d'erreurs: {errors.sum()} sur {len(y_val)} échantillons de validation ({errors.sum()/len(y_val)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des erreurs par classe\n",
    "error_types = pd.DataFrame({\n",
    "    'Réalité': y_val_errors,\n",
    "    'Prédiction': y_val_pred_errors\n",
    "})\n",
    "\n",
    "# Conversion des valeurs numériques en étiquettes\n",
    "error_types['Réalité'] = error_types['Réalité'].map({0: 'Non satisfait', 1: 'Satisfait'})\n",
    "error_types['Prédiction'] = error_types['Prédiction'].map({0: 'Non satisfait', 1: 'Satisfait'})\n",
    "\n",
    "# Comptage des types d'erreurs\n",
    "error_counts = error_types.groupby(['Réalité', 'Prédiction']).size().reset_index(name='Nombre')\n",
    "error_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "Dans ce notebook, nous avons exploré plusieurs modèles de classification pour prédire la satisfaction des passagers :\n",
    "\n",
    "1. **Modèle de base (Dummy Classifier)** : Ce modèle simple nous a fourni une référence de performance.\n",
    "2. **Régression Logistique** : Un modèle linéaire qui a montré de bonnes performances.\n",
    "3. **Arbre de Décision** : Un modèle plus complexe qui peut capturer des relations non linéaires.\n",
    "4. **Random Forest** : Un ensemble d'arbres qui a généralement montré les meilleures performances.\n",
    "5. **SVM** : Un modèle puissant pour la classification avec de bonnes performances.\n",
    "\n",
    "Nous avons également analysé les caractéristiques les plus importantes pour la prédiction et examiné les types d'erreurs commises par notre meilleur modèle.\n",
    "\n",
    "### Prochaines étapes\n",
    "\n",
    "Pour améliorer davantage les performances des modèles, nous pourrions :\n",
    "- Effectuer une optimisation des hyperparamètres pour affiner les modèles\n",
    "- Explorer d'autres techniques de feature engineering\n",
    "- Essayer des modèles plus avancés comme les réseaux de neurones ou le gradient boosting\n",
    "- Traiter le déséquilibre des classes si nécessaire\n",
    "\n",
    "Ces aspects seront abordés dans les prochains notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bahut_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
