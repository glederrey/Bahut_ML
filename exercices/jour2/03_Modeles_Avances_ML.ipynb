{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jour 2 - Exercice 3 : Modèles avancés de Machine Learning\n",
    "\n",
    "## Objectifs\n",
    "- Explorer des modèles de machine learning plus avancés\n",
    "- Implémenter XGBoost pour la classification\n",
    "- Réaliser une optimisation des hyperparamètres\n",
    "- Comparer les performances avec les modèles précédents\n",
    "- Visualiser les résultats avec Plotly\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Dans ce notebook, nous allons approfondir notre analyse en utilisant des modèles de machine learning plus avancés. Nous nous concentrerons particulièrement sur XGBoost, un algorithme puissant basé sur le gradient boosting, et nous explorerons comment optimiser ses hyperparamètres pour améliorer les performances. Nous utiliserons toujours le jeu de données de satisfaction des passagers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement et préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Bibliothèques pour le machine learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Métriques d'évaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Pour afficher plus de colonnes dans les DataFrames\n",
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du jeu de données\n",
    "df = pd.read_csv('../../data/passenger_satisfaction/train.csv')\n",
    "\n",
    "# Affichage des premières lignes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de la distribution de la variable cible\n",
    "target_counts = df['Satisfaction'].value_counts()\n",
    "\n",
    "fig = px.pie(values=target_counts.values, \n",
    "             names=target_counts.index, \n",
    "             title='Distribution de la satisfaction des passagers',\n",
    "             color_discrete_sequence=px.colors.qualitative.Set3)\n",
    "\n",
    "fig.update_traces(textinfo='percent+label')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prétraitement des données\n",
    "\n",
    "Nous allons reprendre les étapes de prétraitement des notebooks précédents pour préparer nos données pour les modèles avancés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression de la colonne ID qui n'est pas utile pour la prédiction\n",
    "df = df.drop('ID', axis=1)\n",
    "\n",
    "# Conversion de la variable cible en valeurs numériques\n",
    "target_mapping = {'neutral or dissatisfied': 0, 'satisfied': 1}\n",
    "df['Satisfaction'] = df['Satisfaction'].map(target_mapping)\n",
    "\n",
    "# Séparation des caractéristiques et de la variable cible\n",
    "X = df.drop('Satisfaction', axis=1)\n",
    "y = df['Satisfaction']\n",
    "\n",
    "# Division en ensembles d'entraînement et de validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identification des caractéristiques numériques et catégorielles\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Caractéristiques numériques: {numeric_features}\")\n",
    "print(f\"Caractéristiques catégorielles: {categorical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un pipeline de prétraitement\n",
    "# Pour les caractéristiques numériques: imputation des valeurs manquantes et standardisation\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pour les caractéristiques catégorielles: imputation des valeurs manquantes et encodage one-hot\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combinaison des transformateurs dans un ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Application du prétraitement aux données d'entraînement et de validation\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_val_preprocessed = preprocessor.transform(X_val)\n",
    "\n",
    "print(f\"Forme des données d'entraînement après prétraitement: {X_train_preprocessed.shape}\")\n",
    "print(f\"Forme des données de validation après prétraitement: {X_val_preprocessed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering avancé\n",
    "\n",
    "Ajoutons quelques features supplémentaires pour améliorer les performances de nos modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une copie des données originales pour le feature engineering\n",
    "X_train_fe = X_train.copy()\n",
    "X_val_fe = X_val.copy()\n",
    "\n",
    "# 1. Création d'une feature pour la satisfaction moyenne des services\n",
    "service_columns = [\n",
    "    'Inflight wifi service', 'Departure/Arrival time convenient', 'Ease of Online booking',\n",
    "    'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',\n",
    "    'Inflight entertainment', 'On-board service', 'Leg room service',\n",
    "    'Baggage handling', 'Checkin service', 'Inflight service', 'Cleanliness'\n",
    "]\n",
    "\n",
    "X_train_fe['Average_Service_Rating'] = X_train_fe[service_columns].mean(axis=1)\n",
    "X_val_fe['Average_Service_Rating'] = X_val_fe[service_columns].mean(axis=1)\n",
    "\n",
    "# 2. Création d'une feature pour le retard total (départ + arrivée)\n",
    "X_train_fe['Total_Delay'] = X_train_fe['Departure Delay in Minutes'] + X_train_fe['Arrival Delay in Minutes'].fillna(0)\n",
    "X_val_fe['Total_Delay'] = X_val_fe['Departure Delay in Minutes'] + X_val_fe['Arrival Delay in Minutes'].fillna(0)\n",
    "\n",
    "# 3. Création d'une feature binaire pour indiquer s'il y a eu un retard\n",
    "X_train_fe['Has_Delay'] = (X_train_fe['Total_Delay'] > 0).astype(int)\n",
    "X_val_fe['Has_Delay'] = (X_val_fe['Total_Delay'] > 0).astype(int)\n",
    "\n",
    "# 4. Création d'une feature pour la variance des évaluations de service\n",
    "X_train_fe['Service_Rating_Variance'] = X_train_fe[service_columns].var(axis=1)\n",
    "X_val_fe['Service_Rating_Variance'] = X_val_fe[service_columns].var(axis=1)\n",
    "\n",
    "# Mise à jour des listes de caractéristiques\n",
    "new_numeric_features = ['Average_Service_Rating', 'Total_Delay', 'Has_Delay', 'Service_Rating_Variance']\n",
    "numeric_features_fe = numeric_features + new_numeric_features\n",
    "categorical_features_fe = categorical_features\n",
    "\n",
    "print(f\"Nouvelles caractéristiques numériques: {new_numeric_features}\")\n",
    "print(f\"Nombre total de caractéristiques numériques après feature engineering: {len(numeric_features_fe)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un nouveau pipeline de prétraitement avec les nouvelles features\n",
    "numeric_transformer_fe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer_fe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor_fe = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer_fe, numeric_features_fe),\n",
    "        ('cat', categorical_transformer_fe, categorical_features_fe)\n",
    "    ])\n",
    "\n",
    "# Application du prétraitement aux données d'entraînement et de validation avec feature engineering\n",
    "X_train_fe_preprocessed = preprocessor_fe.fit_transform(X_train_fe)\n",
    "X_val_fe_preprocessed = preprocessor_fe.transform(X_val_fe)\n",
    "\n",
    "print(f\"Forme des données d'entraînement après feature engineering et prétraitement: {X_train_fe_preprocessed.shape}\")\n",
    "print(f\"Forme des données de validation après feature engineering et prétraitement: {X_val_fe_preprocessed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fonction d'évaluation des modèles\n",
    "\n",
    "Nous allons créer une fonction pour évaluer les performances des différents modèles de manière cohérente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_val, y_train, y_val, model_name):\n",
    "    # Entraînement du modèle\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Prédictions sur l'ensemble d'entraînement et de validation\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calcul des métriques\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    val_precision = precision_score(y_val, y_val_pred)\n",
    "    \n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    val_recall = recall_score(y_val, y_val_pred)\n",
    "    \n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "    val_f1 = f1_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Affichage des métriques\n",
    "    print(f\"Performances du modèle {model_name}:\")\n",
    "    print(f\"Accuracy - Train: {train_accuracy:.4f}, Validation: {val_accuracy:.4f}\")\n",
    "    print(f\"Precision - Train: {train_precision:.4f}, Validation: {val_precision:.4f}\")\n",
    "    print(f\"Recall - Train: {train_recall:.4f}, Validation: {val_recall:.4f}\")\n",
    "    print(f\"F1 Score - Train: {train_f1:.4f}, Validation: {val_f1:.4f}\")\n",
    "    print(\"\\nRapport de classification sur l'ensemble de validation:\")\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    \n",
    "    # Matrice de confusion\n",
    "    cm = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # Visualisation de la matrice de confusion avec Plotly\n",
    "    fig = px.imshow(cm, \n",
    "                    labels=dict(x=\"Prédiction\", y=\"Réalité\", color=\"Nombre\"),\n",
    "                    x=['Non satisfait', 'Satisfait'],\n",
    "                    y=['Non satisfait', 'Satisfait'],\n",
    "                    text_auto=True,\n",
    "                    title=f\"Matrice de confusion - {model_name}\",\n",
    "                    color_continuous_scale='Blues')\n",
    "    fig.update_layout(\n",
    "        title_text=f\"Matrice de confusion - {model_name}\",\n",
    "        xaxis_title=\"Prédiction\",\n",
    "        yaxis_title=\"Réalité\",\n",
    "        coloraxis_colorbar=dict(title=\"Nombre\"),\n",
    "        height=800,\n",
    "        width=800\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    # Courbe ROC si le modèle peut prédire des probabilités\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_val, y_val_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=f'{model_name} (AUC = {roc_auc:.4f})'))\n",
    "        fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Aléatoire', line=dict(dash='dash', color='gray')))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=f'Courbe ROC - {model_name}',\n",
    "            xaxis_title='Taux de faux positifs',\n",
    "            yaxis_title='Taux de vrais positifs',\n",
    "            legend=dict(x=0.7, y=0.1),\n",
    "            width=1000,\n",
    "            height=800\n",
    "        )\n",
    "        fig.show()\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'name': model_name,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'train_precision': train_precision,\n",
    "        'val_precision': val_precision,\n",
    "        'train_recall': train_recall,\n",
    "        'val_recall': val_recall,\n",
    "        'train_f1': train_f1,\n",
    "        'val_f1': val_f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implémentation de XGBoost\n",
    "\n",
    "XGBoost (eXtreme Gradient Boosting) est un algorithme puissant basé sur le gradient boosting qui est souvent utilisé dans les compétitions de machine learning en raison de ses performances élevées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un modèle XGBoost de base\n",
    "xgb_clf = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Évaluation du modèle XGBoost de base avec les données prétraitées standard\n",
    "xgb_results = evaluate_model(xgb_clf, X_train_preprocessed, X_val_preprocessed, y_train, y_val, \"XGBoost (Base)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation du modèle XGBoost de base avec les données prétraitées et feature engineering\n",
    "xgb_fe_results = evaluate_model(xgb_clf, X_train_fe_preprocessed, X_val_fe_preprocessed, y_train, y_val, \"XGBoost (avec Feature Engineering)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optimisation des hyperparamètres de XGBoost\n",
    "\n",
    "Nous allons maintenant optimiser les hyperparamètres de XGBoost pour améliorer ses performances. Nous utiliserons RandomizedSearchCV pour explorer efficacement l'espace des hyperparamètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de l'espace des hyperparamètres à explorer\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5, 6, 8],\n",
    "    'min_child_weight': [1, 3, 5, 7],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1],\n",
    "    'reg_lambda': [0.1, 0.5, 1, 5]\n",
    "}\n",
    "\n",
    "# Création du modèle XGBoost pour l'optimisation\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Configuration de la recherche aléatoire\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # Nombre d'itérations (combinaisons d'hyperparamètres à tester)\n",
    "    scoring='f1',  # Métrique à optimiser\n",
    "    cv=3,  # Validation croisée à 3 plis\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Utiliser tous les cœurs disponibles\n",
    ")\n",
    "\n",
    "# Exécution de la recherche aléatoire sur les données avec feature engineering\n",
    "print(\"Début de l'optimisation des hyperparamètres...\")\n",
    "random_search.fit(X_train_fe_preprocessed, y_train)\n",
    "print(\"Optimisation terminée!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des meilleurs hyperparamètres trouvés\n",
    "print(\"Meilleurs hyperparamètres trouvés:\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "\n",
    "print(f\"\\nMeilleur score F1: {random_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des résultats de la recherche d'hyperparamètres\n",
    "results = pd.DataFrame(random_search.cv_results_)\n",
    "\n",
    "# Création d'un graphique pour visualiser l'impact des hyperparamètres sur le score F1\n",
    "important_params = ['param_n_estimators', 'param_learning_rate', 'param_max_depth', 'param_subsample']\n",
    "fig = make_subplots(rows=2, cols=2, subplot_titles=[param.replace('param_', '') for param in important_params])\n",
    "\n",
    "for i, param in enumerate(important_params):\n",
    "    row = i // 2 + 1\n",
    "    col = i % 2 + 1\n",
    "    \n",
    "    # Conversion des paramètres en valeurs numériques pour le tracé\n",
    "    param_values = results[param].astype(str).astype(float)\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=param_values,\n",
    "            y=results['mean_test_score'],\n",
    "            mode='markers',\n",
    "            marker=dict(size=10, color=results['mean_test_score'], colorscale='Viridis', showscale=False),\n",
    "            text=results['rank_test_score'],\n",
    "            name=param.replace('param_', '')\n",
    "        ),\n",
    "        row=row, col=col\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text=param.replace('param_', ''), row=row, col=col)\n",
    "    fig.update_yaxes(title_text='Score F1', row=row, col=col)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Impact des hyperparamètres sur le score F1\",\n",
    "    height=800,\n",
    "    width=1000,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un modèle XGBoost avec les meilleurs hyperparamètres\n",
    "best_xgb = xgb.XGBClassifier(**random_search.best_params_, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Évaluation du modèle XGBoost optimisé\n",
    "best_xgb_results = evaluate_model(best_xgb, X_train_fe_preprocessed, X_val_fe_preprocessed, y_train, y_val, \"XGBoost (Optimisé)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyse des caractéristiques importantes\n",
    "\n",
    "XGBoost nous permet d'analyser l'importance des différentes caractéristiques dans le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtention des noms des caractéristiques après transformation\n",
    "# Pour les caractéristiques numériques\n",
    "numeric_features_transformed = numeric_features_fe\n",
    "\n",
    "# Pour les caractéristiques catégorielles (après one-hot encoding)\n",
    "categorical_features_transformed = []\n",
    "for cat_feature in categorical_features_fe:\n",
    "    # Obtention des catégories uniques pour chaque caractéristique catégorielle\n",
    "    unique_categories = X_train_fe[cat_feature].unique()\n",
    "    # Création des noms de colonnes après one-hot encoding (en excluant la première catégorie)\n",
    "    for category in unique_categories[1:]:\n",
    "        categorical_features_transformed.append(f\"{cat_feature}_{category}\")\n",
    "\n",
    "# Combinaison des noms de caractéristiques\n",
    "all_features_transformed = numeric_features_transformed + categorical_features_transformed\n",
    "\n",
    "# Vérification de la longueur\n",
    "print(f\"Nombre de caractéristiques après transformation: {len(all_features_transformed)}\")\n",
    "print(f\"Forme des données prétraitées: {X_train_fe_preprocessed.shape[1]}\")\n",
    "\n",
    "# Ajustement si nécessaire (si les dimensions ne correspondent pas)\n",
    "if len(all_features_transformed) != X_train_fe_preprocessed.shape[1]:\n",
    "    print(\"Attention: Le nombre de noms de caractéristiques ne correspond pas à la dimension des données prétraitées.\")\n",
    "    # Utilisation d'indices numériques si les noms ne correspondent pas\n",
    "    all_features_transformed = [f\"Feature_{i}\" for i in range(X_train_fe_preprocessed.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction de l'importance des caractéristiques du modèle XGBoost optimisé\n",
    "feature_importance = best_xgb.feature_importances_\n",
    "\n",
    "# Création d'un DataFrame pour visualiser l'importance des caractéristiques\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': all_features_transformed,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Affichage des 20 caractéristiques les plus importantes\n",
    "top_20_features = importance_df.head(20)\n",
    "top_20_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des 20 caractéristiques les plus importantes\n",
    "fig = px.bar(top_20_features, \n",
    "             x='Importance', \n",
    "             y='Feature', \n",
    "             orientation='h',\n",
    "             title='Top 20 des caractéristiques les plus importantes (XGBoost optimisé)',\n",
    "             color='Importance',\n",
    "             color_continuous_scale='Viridis')\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Importance',\n",
    "    yaxis_title='Caractéristique',\n",
    "    height=800,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparaison avec d'autres modèles avancés\n",
    "\n",
    "Comparons maintenant XGBoost avec d'autres modèles avancés comme LightGBM et CatBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques pour LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Création d'un modèle LightGBM\n",
    "lgb_clf = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Évaluation du modèle LightGBM\n",
    "lgb_results = evaluate_model(lgb_clf, X_train_fe_preprocessed, X_val_fe_preprocessed, y_train, y_val, \"LightGBM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un modèle AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_clf = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# Évaluation du modèle AdaBoost\n",
    "ada_results = evaluate_model(ada_clf, X_train_fe_preprocessed, X_val_fe_preprocessed, y_train, y_val, \"AdaBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Comparaison finale des modèles\n",
    "\n",
    "Comparons maintenant tous les modèles que nous avons implémentés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un DataFrame pour comparer les modèles\n",
    "results = [xgb_results, xgb_fe_results, best_xgb_results, lgb_results, ada_results]\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Modèle': [result['name'] for result in results],\n",
    "    'Accuracy (Train)': [result['train_accuracy'] for result in results],\n",
    "    'Accuracy (Validation)': [result['val_accuracy'] for result in results],\n",
    "    'Precision (Validation)': [result['val_precision'] for result in results],\n",
    "    'Recall (Validation)': [result['val_recall'] for result in results],\n",
    "    'F1 Score (Validation)': [result['val_f1'] for result in results]\n",
    "})\n",
    "\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des performances des modèles\n",
    "metrics = ['Accuracy (Validation)', 'Precision (Validation)', 'Recall (Validation)', 'F1 Score (Validation)']\n",
    "model_names = comparison_df['Modèle']\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for metric in metrics:\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=model_names,\n",
    "        y=comparison_df[metric],\n",
    "        name=metric\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Comparaison des performances des modèles avancés',\n",
    "    xaxis_title='Modèle',\n",
    "    yaxis_title='Score',\n",
    "    barmode='group',\n",
    "    width=1000,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'écart entre les performances d'entraînement et de validation (pour détecter le surapprentissage)\n",
    "comparison_df['Écart Accuracy'] = comparison_df['Accuracy (Train)'] - comparison_df['Accuracy (Validation)']\n",
    "\n",
    "fig = px.bar(comparison_df, \n",
    "             x='Modèle', \n",
    "             y='Écart Accuracy',\n",
    "             title='Écart entre Accuracy d\\'entraînement et de validation (indicateur de surapprentissage)',\n",
    "             color='Écart Accuracy',\n",
    "             color_continuous_scale='RdYlGn_r')\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Modèle',\n",
    "    yaxis_title='Écart d\\'Accuracy (Train - Validation)',\n",
    "    height=500,\n",
    "    width=900\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "Dans ce notebook, nous avons exploré des modèles de machine learning plus avancés, en nous concentrant particulièrement sur XGBoost avec optimisation des hyperparamètres. Nous avons également comparé XGBoost avec d'autres algorithmes de boosting comme LightGBM et CatBoost.\n",
    "\n",
    "### Points clés à retenir :\n",
    "\n",
    "1. **Feature Engineering** : L'ajout de nouvelles caractéristiques a permis d'améliorer les performances des modèles.\n",
    "\n",
    "2. **Optimisation des hyperparamètres** : L'optimisation des hyperparamètres de XGBoost a conduit à une amélioration significative des performances.\n",
    "\n",
    "3. **Importance des caractéristiques** : L'analyse de l'importance des caractéristiques nous a permis d'identifier les facteurs les plus déterminants pour la satisfaction des passagers.\n",
    "\n",
    "4. **Comparaison des modèles** : Les modèles de boosting (XGBoost, LightGBM, CatBoost) ont généralement montré de meilleures performances que les modèles plus simples.\n",
    "\n",
    "5. **Surapprentissage** : Certains modèles ont montré des signes de surapprentissage, avec un écart important entre les performances d'entraînement et de validation.\n",
    "\n",
    "### Prochaines étapes :\n",
    "\n",
    "- Utiliser la validation croisée pour obtenir une estimation plus robuste des performances des modèles\n",
    "- Explorer des techniques d'ensemble learning pour combiner les prédictions de différents modèles\n",
    "- Tester les modèles sur l'ensemble de test pour évaluer leur généralisation\n",
    "- Déployer le meilleur modèle dans un environnement de production"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bahut_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
