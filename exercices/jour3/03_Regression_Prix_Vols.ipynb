{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jour 3 - Exercice 3 : Régression pour la Prédiction des Prix de Vols\n",
    "\n",
    "## Objectifs\n",
    "- Appliquer les techniques de machine learning à un problème de régression réel\n",
    "- Utiliser les données de prix de vols pour prédire le prix d'un billet d'avion\n",
    "- Évaluer les performances des modèles sur un jeu de test\n",
    "- Visualiser et interpréter les résultats avec Plotly\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Dans ce notebook, nous allons travailler sur un problème de régression : prédire le prix d'un billet d'avion en fonction de différentes caractéristiques du vol. Nous utiliserons les données de prix de vols et appliquerons différentes techniques de machine learning pour construire et évaluer des modèles de régression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement et exploration des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Visualisation avec Plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Scikit-learn pour le machine learning\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Modèles de régression\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Ajouter le chemin pour importer utils.py\n",
    "sys.path.append(os.path.abspath('./'))\n",
    "from utils import results_predictions_prices\n",
    "\n",
    "# Pour afficher plus de colonnes dans les DataFrames\n",
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données d'entraînement\n",
    "train_df = pd.read_csv('../../data/flight_prices/train.csv')\n",
    "\n",
    "# Affichage des premières lignes\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informations sur le DataFrame\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques descriptives\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification des valeurs manquantes\n",
    "missing_values = train_df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(train_df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Values': missing_values,\n",
    "    'Percentage': missing_percentage\n",
    "})\n",
    "\n",
    "# Affichage des valeurs manquantes\n",
    "missing_df[missing_df['Missing Values'] > 0].sort_values('Missing Values', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyse exploratoire des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution de la variable cible (Prix)\n",
    "fig = px.histogram(train_df, x='Price', nbins=50, title='Distribution des Prix des Vols')\n",
    "fig.update_layout(xaxis_title='Prix', yaxis_title='Fréquence')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion des dates en format datetime\n",
    "train_df['Searched Date'] = pd.to_datetime(train_df['Searched Date'])\n",
    "train_df['Departure Date'] = pd.to_datetime(train_df['Departure Date'])\n",
    "train_df['Arrival Date'] = pd.to_datetime(train_df['Arrival Date'])\n",
    "\n",
    "# Extraction de caractéristiques temporelles\n",
    "train_df['Search_Month'] = train_df['Searched Date'].dt.month\n",
    "train_df['Search_Day'] = train_df['Searched Date'].dt.day\n",
    "train_df['Search_DayOfWeek'] = train_df['Searched Date'].dt.dayofweek\n",
    "\n",
    "train_df['Departure_Month'] = train_df['Departure Date'].dt.month\n",
    "train_df['Departure_Day'] = train_df['Departure Date'].dt.day\n",
    "train_df['Departure_DayOfWeek'] = train_df['Departure Date'].dt.dayofweek\n",
    "train_df['Departure_Hour'] = train_df['Departure Date'].dt.hour\n",
    "\n",
    "train_df['Arrival_Month'] = train_df['Arrival Date'].dt.month\n",
    "train_df['Arrival_Day'] = train_df['Arrival Date'].dt.day\n",
    "train_df['Arrival_DayOfWeek'] = train_df['Arrival Date'].dt.dayofweek\n",
    "train_df['Arrival_Hour'] = train_df['Arrival Date'].dt.hour\n",
    "\n",
    "# Calcul de la durée du vol en heures\n",
    "train_df['Flight_Duration_Hours'] = (train_df['Arrival Date'] - train_df['Departure Date']).dt.total_seconds() / 3600\n",
    "\n",
    "# Calcul du nombre de jours entre la recherche et le départ\n",
    "train_df['Days_Before_Departure'] = (train_df['Departure Date'] - train_df['Searched Date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation du prix en fonction de la durée du vol\n",
    "fig = px.scatter(train_df, x='Flight_Duration_Hours', y='Price', color='Cabin',\n",
    "                 title='Prix en fonction de la Durée du Vol',\n",
    "                 labels={'Flight_Duration_Hours': 'Durée du Vol (heures)', 'Price': 'Prix'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation du prix en fonction du nombre de jours avant le départ\n",
    "fig = px.scatter(train_df, x='Days_Before_Departure', y='Price', color='Cabin',\n",
    "                 title='Prix en fonction du Nombre de Jours avant le Départ',\n",
    "                 labels={'Days_Before_Departure': 'Jours avant le Départ', 'Price': 'Prix'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prix moyen par compagnie aérienne\n",
    "airline_price = train_df.groupby('Airline')['Price'].mean().reset_index().sort_values('Price', ascending=False)\n",
    "\n",
    "fig = px.bar(airline_price, x='Airline', y='Price',\n",
    "             title='Prix Moyen par Compagnie Aérienne',\n",
    "             labels={'Airline': 'Compagnie Aérienne', 'Price': 'Prix Moyen'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prix moyen par classe de cabine\n",
    "cabin_price = train_df.groupby('Cabin')['Price'].mean().reset_index().sort_values('Price', ascending=False)\n",
    "\n",
    "fig = px.bar(cabin_price, x='Cabin', y='Price',\n",
    "             title='Prix Moyen par Classe de Cabine',\n",
    "             labels={'Cabin': 'Classe de Cabine', 'Price': 'Prix Moyen'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prix moyen par nombre d'escales\n",
    "stops_price = train_df.groupby('Number Of Stops')['Price'].mean().reset_index().sort_values('Number Of Stops')\n",
    "\n",
    "fig = px.bar(stops_price, x='Number Of Stops', y='Price',\n",
    "             title='Prix Moyen par Nombre d\\'Escales',\n",
    "             labels={'Number Of Stops': 'Nombre d\\'Escales', 'Price': 'Prix Moyen'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Préparation des données pour la modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la durée du vol en heures\n",
    "train_df['Flight_Duration_Hours'] = (train_df['Arrival Date'] - train_df['Departure Date']).dt.total_seconds() / 3600\n",
    "\n",
    "# Calcul du nombre de jours entre la recherche et le départ\n",
    "train_df['Days_Before_Departure'] = (train_df['Departure Date'] - train_df['Searched Date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des caractéristiques pour la modélisation\n",
    "# Nous excluons les colonnes de date brutes et utilisons les caractéristiques extraites\n",
    "features = [\n",
    "    'Departure Airport', 'Arrival Airport', 'Number Of Stops', 'Airline', 'Cabin',\n",
    "    'Flight Lands Next Day', 'Search_Month', 'Search_Day', 'Search_DayOfWeek',\n",
    "    'Departure_Month', 'Departure_Day', 'Departure_DayOfWeek', 'Departure_Hour',\n",
    "    'Arrival_Month', 'Arrival_Day', 'Arrival_DayOfWeek', 'Arrival_Hour',\n",
    "    'Flight_Duration_Hours', 'Days_Before_Departure'\n",
    "]\n",
    "\n",
    "# Variable cible\n",
    "target = 'Price'\n",
    "\n",
    "# Séparation des caractéristiques et de la cible\n",
    "X = train_df[features]\n",
    "y = train_df[target]\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identification des colonnes numériques et catégorielles\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "\n",
    "print(f\"Caractéristiques numériques: {numeric_features}\")\n",
    "print(f\"Caractéristiques catégorielles: {categorical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un préprocesseur pour les données\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Préparation des données d'entraînement et de validation\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "\n",
    "print(f\"Forme des données d'entraînement transformées: {X_train_processed.shape}\")\n",
    "print(f\"Forme des données de validation transformées: {X_val_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modélisation et évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour évaluer les modèles\n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val):\n",
    "    # Entraînement du modèle\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Prédictions sur l'ensemble de validation\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calcul des métriques\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'model': model.__class__.__name__,\n",
    "        'mae': mae,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'model_object': model\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des modèles\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=1.0),\n",
    "    Lasso(alpha=0.2),\n",
    "    ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
    "    DecisionTreeRegressor(max_depth=10, random_state=42),\n",
    "    RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42),\n",
    "    GradientBoostingRegressor(n_estimators=50, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "]\n",
    "\n",
    "# Évaluation des modèles\n",
    "results = []\n",
    "for model in models:\n",
    "    print(\"Training model: \", model.__class__.__name__)\n",
    "    result = evaluate_model(model, X_train_processed, y_train, X_val_processed, y_val)\n",
    "    results.append(result)\n",
    "    \n",
    "# Création d'un DataFrame avec les résultats\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.drop('model_object', axis=1)\n",
    "results_df.sort_values('mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des résultats\n",
    "fig = px.bar(results_df, x='model', y='mae', title='Erreur Absolue Moyenne (MAE) par Modèle',\n",
    "             labels={'model': 'Modèle', 'mae': 'MAE'},\n",
    "             color='mae', color_continuous_scale='Viridis')\n",
    "fig.update_layout(xaxis_tickangle=-45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des résultats (R²)\n",
    "fig = px.bar(results_df, x='model', y='r2', title='Coefficient de Détermination (R²) par Modèle',\n",
    "             labels={'model': 'Modèle', 'r2': 'R²'},\n",
    "             color='r2', color_continuous_scale='Viridis')\n",
    "fig.update_layout(xaxis_tickangle=-45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection du meilleur modèle (basé sur MAE)\n",
    "best_model_idx = results_df['mae'].idxmin()\n",
    "best_model_name = results_df.loc[best_model_idx, 'model']\n",
    "best_model = results[best_model_idx]['model_object']\n",
    "\n",
    "print(f\"Le meilleur modèle est {best_model_name} avec une MAE de {results_df.loc[best_model_idx, 'mae']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des prédictions vs valeurs réelles pour le meilleur modèle\n",
    "y_pred = best_model.predict(X_val_processed)\n",
    "\n",
    "fig = px.scatter(x=y_val, y=y_pred, title=f'Valeurs Réelles vs Prédictions ({best_model_name})',\n",
    "                 labels={'x': 'Valeurs Réelles', 'y': 'Prédictions'})\n",
    "\n",
    "# Ajout de la ligne d'identité (y=x)\n",
    "fig.add_trace(go.Scatter(x=[y_val.min(), y_val.max()], y=[y_val.min(), y_val.max()],\n",
    "                         mode='lines', name='y=x', line=dict(color='red', dash='dash')))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la distribution des erreurs\n",
    "errors = y_val - y_pred\n",
    "\n",
    "fig = px.histogram(errors, nbins=50, title='Distribution des Erreurs de Prédiction',\n",
    "                   labels={'value': 'Erreur', 'count': 'Fréquence'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Évaluation sur le jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données d'entraînement et de test\n",
    "train_df = pd.read_csv('../../data/flight_prices/train.csv')\n",
    "test_df = pd.read_csv('../../data/flight_prices/test.csv')\n",
    "\n",
    "# Affichage des premières lignes du jeu de test\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour préparer les données\n",
    "def prepare_data(df):\n",
    "    # Conversion des dates en format datetime\n",
    "    df['Searched Date'] = pd.to_datetime(df['Searched Date'])\n",
    "    df['Departure Date'] = pd.to_datetime(df['Departure Date'])\n",
    "    df['Arrival Date'] = pd.to_datetime(df['Arrival Date'])\n",
    "    \n",
    "    # Extraction de caractéristiques temporelles\n",
    "    df['Search_Month'] = df['Searched Date'].dt.month\n",
    "    df['Search_Day'] = df['Searched Date'].dt.day\n",
    "    df['Search_DayOfWeek'] = df['Searched Date'].dt.dayofweek\n",
    "    \n",
    "    df['Departure_Month'] = df['Departure Date'].dt.month\n",
    "    df['Departure_Day'] = df['Departure Date'].dt.day\n",
    "    df['Departure_DayOfWeek'] = df['Departure Date'].dt.dayofweek\n",
    "    df['Departure_Hour'] = df['Departure Date'].dt.hour\n",
    "    \n",
    "    df['Arrival_Month'] = df['Arrival Date'].dt.month\n",
    "    df['Arrival_Day'] = df['Arrival Date'].dt.day\n",
    "    df['Arrival_DayOfWeek'] = df['Arrival Date'].dt.dayofweek\n",
    "    df['Arrival_Hour'] = df['Arrival Date'].dt.hour\n",
    "    \n",
    "    # Calcul de la durée du vol en heures\n",
    "    df['Flight_Duration_Hours'] = (df['Arrival Date'] - df['Departure Date']).dt.total_seconds() / 3600\n",
    "    \n",
    "    # Calcul du nombre de jours entre la recherche et le départ\n",
    "    df['Days_Before_Departure'] = (df['Departure Date'] - df['Searched Date']).dt.days\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données d'entraînement et de test\n",
    "train_df = prepare_data(train_df)\n",
    "test_df = prepare_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des caractéristiques pour la modélisation\n",
    "features = [\n",
    "    'Departure Airport', 'Arrival Airport', 'Number Of Stops', 'Airline', 'Cabin',\n",
    "    'Flight Lands Next Day', 'Search_Month', 'Search_Day', 'Search_DayOfWeek',\n",
    "    'Departure_Month', 'Departure_Day', 'Departure_DayOfWeek', 'Departure_Hour',\n",
    "    'Arrival_Month', 'Arrival_Day', 'Arrival_DayOfWeek', 'Arrival_Hour',\n",
    "    'Flight_Duration_Hours', 'Days_Before_Departure'\n",
    "]\n",
    "\n",
    "# Variable cible\n",
    "target = 'Price'\n",
    "\n",
    "# Séparation des caractéristiques et de la cible pour l'entraînement\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[target]\n",
    "\n",
    "# Préparation des données de test\n",
    "X_test = test_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identification des colonnes numériques et catégorielles\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "\n",
    "# Création d'un préprocesseur pour les données\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement des modèles sur l'ensemble complet d'entraînement\n",
    "# Nous allons entraîner plusieurs modèles et les évaluer sur le jeu de test\n",
    "\n",
    "# Préparation des données d'entraînement\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Préparation des données de test\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"Forme des données d'entraînement transformées: {X_train_processed.shape}\")\n",
    "print(f\"Forme des données de test transformées: {X_test_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création et entraînement des modèles\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'Lasso': Lasso(alpha=0.2),\n",
    "    'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
    "    'Decision Tree': DecisionTreeRegressor(max_depth=10, random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "}\n",
    "\n",
    "# Entraînement des modèles\n",
    "for name, model in models.items():\n",
    "    print(f\"Entraînement du modèle {name}...\")\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    print(f\"Modèle {name} entraîné avec succès.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions sur le jeu de test avec le modèle Gradient Boosting\n",
    "# (généralement l'un des plus performants pour ce type de problème)\n",
    "best_model = models['Gradient Boosting']\n",
    "y_pred_test = best_model.predict(X_test_processed)\n",
    "\n",
    "# Affichage des premières prédictions\n",
    "pd.DataFrame({'Prédictions': y_pred_test}).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation des performances sur le jeu de test en utilisant la fonction results_predictions_prices\n",
    "mae_test = results_predictions_prices(y_pred_test)\n",
    "print(f\"Erreur Absolue Moyenne (MAE) sur le jeu de test: {mae_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparaison des performances des différents modèles sur le jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation de tous les modèles sur le jeu de test\n",
    "test_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Prédictions sur le jeu de test\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    \n",
    "    # Calcul de la MAE en utilisant la fonction results_predictions_prices\n",
    "    mae = results_predictions_prices(y_pred)\n",
    "    \n",
    "    test_results.append({\n",
    "        'model': name,\n",
    "        'mae': mae\n",
    "    })\n",
    "    \n",
    "# Création d'un DataFrame avec les résultats\n",
    "test_results_df = pd.DataFrame(test_results)\n",
    "test_results_df.sort_values('mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des résultats sur le jeu de test\n",
    "fig = px.bar(test_results_df, x='model', y='mae', title='Erreur Absolue Moyenne (MAE) par Modèle sur le Jeu de Test',\n",
    "             labels={'model': 'Modèle', 'mae': 'MAE'},\n",
    "             color='mae', color_continuous_scale='Viridis')\n",
    "fig.update_layout(xaxis_tickangle=-45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyse des caractéristiques importantes (pour le modèle Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des noms des caractéristiques après transformation\n",
    "feature_names = []\n",
    "\n",
    "# Pour les caractéristiques numériques\n",
    "feature_names.extend(numeric_features)\n",
    "\n",
    "# Pour les caractéristiques catégorielles, nous devons extraire les noms des colonnes après one-hot encoding\n",
    "# Nous allons créer une liste temporaire pour simuler les noms\n",
    "categorical_feature_names = []\n",
    "for feature in categorical_features:\n",
    "    unique_values = X_train[feature].unique()\n",
    "    for value in unique_values:\n",
    "        categorical_feature_names.append(f\"{feature}_{value}\")\n",
    "\n",
    "feature_names.extend(categorical_feature_names)\n",
    "\n",
    "# Analyse des caractéristiques importantes pour le modèle Random Forest\n",
    "rf_model = models['Random Forest']\n",
    "\n",
    "# Extraction des importances des caractéristiques\n",
    "importances = {}\n",
    "\n",
    "# Pour les caractéristiques numériques\n",
    "for i, feature in enumerate(numeric_features):\n",
    "    importances[feature] = rf_model.feature_importances_[i]\n",
    "\n",
    "# Pour les caractéristiques catégorielles\n",
    "start_idx = len(numeric_features)\n",
    "for feature in categorical_features:\n",
    "    unique_values = X_train[feature].unique()\n",
    "    feature_importance = 0\n",
    "    for value in unique_values:\n",
    "        feature_importance += rf_model.feature_importances_[start_idx]\n",
    "        start_idx += 1\n",
    "    importances[feature] = feature_importance\n",
    "\n",
    "# Création d'un DataFrame pour visualiser les importances\n",
    "importances_df = pd.DataFrame({\n",
    "    'Feature': list(importances.keys()),\n",
    "    'Importance': list(importances.values())\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Affichage des 10 caractéristiques les plus importantes\n",
    "importances_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des importances des caractéristiques\n",
    "fig = px.bar(importances_df.head(10), x='Importance', y='Feature', orientation='h',\n",
    "             title='Top 10 des Caractéristiques les Plus Importantes (Random Forest)',\n",
    "             labels={'Importance': 'Importance', 'Feature': 'Caractéristique'},\n",
    "             color='Importance', color_continuous_scale='Viridis')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "Dans ce notebook, nous avons exploré un problème de régression pour prédire le prix des vols en fonction de différentes caractéristiques. Nous avons :\n",
    "\n",
    "1. Chargé et exploré les données de prix de vols\n",
    "2. Effectué une analyse exploratoire des données pour comprendre les relations entre les variables\n",
    "3. Préparé les données pour la modélisation en extrayant des caractéristiques pertinentes\n",
    "4. Entraîné plusieurs modèles de régression et évalué leurs performances\n",
    "5. Utilisé le jeu de test pour évaluer les performances finales des modèles\n",
    "6. Analysé les caractéristiques les plus importantes pour la prédiction des prix\n",
    "\n",
    "Les résultats montrent que les modèles d'ensemble comme le Random Forest et le Gradient Boosting sont les plus performants pour ce problème de régression. Les caractéristiques les plus importantes pour la prédiction des prix incluent la durée du vol, le nombre de jours avant le départ, et la classe de cabine.\n",
    "\n",
    "Pour améliorer davantage les performances, nous pourrions :\n",
    "- Effectuer une optimisation des hyperparamètres plus poussée\n",
    "- Explorer d'autres techniques de feature engineering\n",
    "- Essayer des modèles plus avancés comme les réseaux de neurones\n",
    "- Combiner plusieurs modèles en utilisant des techniques d'ensemble plus sophistiquées"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bahut_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
